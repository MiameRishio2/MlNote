多层感知机
感知机是由输入层，隐藏层和输出层组成的。可以被看作一组输入向量到一组输出向量的映射。
对于一组样本X(n, d)，批量大小为n，输入特征为d。
假设只有一个隐藏层，其中隐藏单位个数为h，出输出为H(n, h)。
隐藏层和输出层之间之间为全连接，则Wh(d, h) bh(1, h)
输出层的权重和偏差Wo(h, q) bo(1, q)，
假设输出为O(n, q)
可以得到公式
H = X * Wh + bh
O = H * Wo + b0
整理可得
O = (X * Wh + bh) * Wo + bo = X * Wh * Wo + bh * Wo + b0
效果与单层神经网络相同

所以在要在全连接层结尾插入一个非线性变换，在这样的非线性函数被称之为激活函数。
一般常用的激活函数有：
RELU函数： 
ReLU(x) = max(x, 0)

Sigmoid函数：
sigmoid(x) = 1 / (1 + exp(-x))

tanh函数：
tanh(x) = (1 - exp(-2 * x)) / (1 + exp(-2 * x))

激活函数的选择
在大部分的时候，ReLU函数因为计算量少，优先被选择。
在二分类时，选择sigmoid函数可能效果会更好。